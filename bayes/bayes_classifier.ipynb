{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6baf6d6",
   "metadata": {},
   "source": [
    "# Khái niệm cơ bản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b8757",
   "metadata": {},
   "source": [
    "Hàm mật độ xác suất:\n",
    "+ biểu thị mức độ tập trung của xác suất quanh điểm đó, giá trị lớn thì khả năng xuất hiện của biến ngẫu nhiên tại điểm đó lớn hơn.\n",
    "\n",
    "Hàm phân phối xác suất:\n",
    "+ là xác suất mà biến ngẫu nhiên có giá trị nhỏ hơn hoặc bằng một giá trị nào đó.\n",
    "+ là tích phân của hàm mật độ xác suất với khoảng từ - vô cực đến x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d90ad",
   "metadata": {},
   "source": [
    "# Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7280f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[iris.feature_names], df['target'], test_size=0.2, random_state=42, stratify=df['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d93cf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    5.841667\n",
       "sepal width (cm)     3.048333\n",
       "petal length (cm)    3.770000\n",
       "petal width (cm)     1.205000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.means = None\n",
    "        self.variances = None\n",
    "        self.labels = None\n",
    "        self.nclasses = None\n",
    "        self.mean = {}\n",
    "        self.variance = {}\n",
    "        self.pk = {}\n",
    "        self.pxk = []\n",
    "\n",
    "    def get_mean_variance(self, X, label):\n",
    "        if self.mean.get(label) is None:\n",
    "            self.mean[label] = np.mean(X, axis=0)\n",
    "        if self.variance.get(label) is None:\n",
    "            self.variance[label] = np.var(X, axis=0)\n",
    "        # self.mean = np.mean(X, axis=0)\n",
    "        # self.variance = np.var(X, axis=0)\n",
    "        # return self.mean, self.variance\n",
    "    \n",
    "    def adf(self, X, mean, variance):\n",
    "        return (1 / np.sqrt(2 * np.pi * variance)) * np.exp(-((X - mean) ** 2) / (2 * variance))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.nclasses = len(np.unique(y))\n",
    "        self.labels = np.unique(y)\n",
    "        for i in np.unique(y):\n",
    "            X_i = X[y == i]\n",
    "            self.get_mean_variance(X_i, i)\n",
    "            self.pk[i] = len(X_i) / len(X)\n",
    "\n",
    "            # self.pxk.append(self.adf(X_i, self.mean, self.variance))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        res = []\n",
    "        for i in X_test:\n",
    "            value = []\n",
    "            for j in self.labels:\n",
    "                pxk = self.adf(i, self.mean[j], self.variance[j])\n",
    "                value.append(np.prod(pxk) * self.pk[j])\n",
    "            res.append(self.labels[np.argmax(value)])\n",
    "        return res\n",
    "    \n",
    "    def evaluate(self, y_test, y_pred):\n",
    "        return np.sum(y_test == y_pred) / len(y_test) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ea1acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0), np.int64(2), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(2), np.int64(0), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(1), np.int64(0), np.int64(2), np.int64(0)]\n",
      "Độ chính xác: 96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNaiveBayes()\n",
    "gnb.fit(X_train.values, y_train.values)\n",
    "predict = gnb.predict(X_test.values)\n",
    "print(predict)\n",
    "print('Độ chính xác:', gnb.evaluate(y_test.values, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f733fa0",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "178082e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "# print(data.data[0])  # Văn bản đầu tiên\n",
    "# print(data.target[0])  # Nhãn của văn bản đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "392d4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.pk = {}\n",
    "        self.pxk = {}\n",
    "        self.labels = None\n",
    "        self.nclasses = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.nclasses = len(np.unique(y))\n",
    "        self.labels = np.unique(y)\n",
    "        \n",
    "        for i in np.unique(y):\n",
    "            if self.pxk.get(i) is None:\n",
    "                self.pxk[i] = {}\n",
    "            \n",
    "            for j in range(X.shape[1]):\n",
    "                if self.pxk[i].get(j) is None:\n",
    "                    self.pxk[i][j] = {}\n",
    "        \n",
    "\n",
    "        for i in np.unique(y):\n",
    "            X_i = X[y == i]\n",
    "            self.pk[i] = len(X_i) / len(X)\n",
    "            for j in range(X.shape[1]):\n",
    "                for k in np.unique(X[:, j]):\n",
    "                    self.pxk[i][j][k] = (np.sum(X_i[:, j] == k) + 1) / (len(X_i) + len(np.unique(X[:, j])))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        res = []\n",
    "        for i in X_test:\n",
    "            value = []\n",
    "            for j in self.labels:\n",
    "                pxk = []\n",
    "                for index, k in enumerate(i):\n",
    "                    pxk.append(self.pxk[j][index].get(k, 1e-6))\n",
    "                value.append(np.prod(pxk) * self.pk[j])\n",
    "            res.append(self.labels[np.argmax(value)])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "492f3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_fn = 'data/train-features.txt'\n",
    "test_data_fn = 'data/test-features.txt'\n",
    "train_label_fn = 'data/train-labels.txt'\n",
    "test_label_fn = 'data/test-labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e47093a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords = 2500\n",
    "\n",
    "def read_data(data_fn, label_fn):\n",
    "  ## read label_fn\n",
    "  with open(label_fn) as f:\n",
    "    content = f.readlines()\n",
    "  label = [int(x.strip()) for x in content]\n",
    "  with open(data_fn) as f:\n",
    "    content = f.readlines()\n",
    "  # remove '\\n' at the end of each line\n",
    "  content = [x.strip() for x in content]\n",
    "\n",
    "  dat = np.zeros((len(content), 3), dtype = int)\n",
    "\n",
    "  for i, line in enumerate(content):\n",
    "    a = line.split(' ')\n",
    "    dat[i, :] = np.array([int(a[0]), int(a[1]), int(a[2])])\n",
    "\n",
    "  data = coo_matrix((dat[:, 2], (dat[:, 0] - 1, dat[:, 1] - 1)),\\\n",
    "    shape=(len(label), nwords))\n",
    "  return (data, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7193df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label) = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label) = read_data(test_data_fn, test_label_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1ee064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2500)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.toarray()\n",
    "test_data = test_data.toarray()\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31cf357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [ 3,  2, 17, ...,  0,  0,  3]], shape=(700, 2500))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác: 74.61538461538461\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNaiveBayes()\n",
    "mnb.fit(train_data, train_label)\n",
    "predict = mnb.predict(test_data)\n",
    "# predict = np.array(predict)\n",
    "# test_label = np.array(test_label)\n",
    "# print('Độ chính xác:', np.sum(predict == test_label) / len(test_label) * 100)\n",
    "print('Độ chính xác:', np.sum(predict == test_label) / len(test_label) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
